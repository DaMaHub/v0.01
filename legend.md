Imagine a global network of document repositories in public libraries. Each one hosts all open access articles relevant to the libraries’ users, maybe even with the published research data from the articles. The repositories update and distribute newly published articles among themselves without manual interaction, serving both as an archive and a front-end library. 
 
Articles can be stored in any format together with underlying research data. The repository’s host can decide which data to host (for example only host data for local researchers), and if a user wants to access off-site data or articles, the network will deliver them immediately from the sites that have them available. All events on the repository such as uploads or metadata changes are published on a permissioned blockchain, that serves as the feed that connects all repositories and allows newly set up repositories to quickly access all requested articles and local data. 

While all repositories form a network, each one is also independent of the rest, thereby making the network resilient against local breakdowns or attacks. If the libraries’ connection to the outside fails, all  hosted articles and hosted data are  still available locally. One publisher’s home repository goes down? No problem, other repositories that host its articles and data serve it as well; therefore, the requesting user will not even notice the outage. A library in a war zone asks for help to save all their hosted publications? Repositories worldwide can be set to quickly mirror all publications from the endangered library, looking up all references published by that library on the blockchain.

Search services can be done locally, de-centralised, and keeping bandwidth and server usage low. Researchers that want to mine large numbers of articles are encouraged to set up their own simple client repository for this either on their local computer or on the web, thus not putting any load on the local library repository server or the network apart from the initial data download.
 
Existing open access publications can be imported into the network and made available immediately.
 
We believe that to make science open, a data management solution has to fit into the daily data workflow of a researcher. Therefore  Data Management Hub is a combination of a distributed Open Science platform together with a local client on the researcher’s computer. The local client allows data to be shared privately and securely with colleagues, as well as providing data versioning and effortless archiving.